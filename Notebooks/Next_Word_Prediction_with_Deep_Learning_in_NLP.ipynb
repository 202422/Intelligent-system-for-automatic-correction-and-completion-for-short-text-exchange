{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "REhRO6uS2sMy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import regex as re\n",
        "from sklearn.model_selection import train_test_split # Pour split training/validation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def file_to_sentence_list(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file: # Ajout de l'encodage\n",
        "        text = file.read()\n",
        "    sentences = [sentence.strip() for sentence in re.split(\n",
        "        r'(?<=[.!?])\\s+', text) if sentence.strip()]\n",
        "    return sentences\n",
        "\n",
        "file_path = 'output.txt'\n",
        "text_data = file_to_sentence_list(file_path)\n",
        "\n",
        "# 1. Tokenisation (peut toujours être fait une fois si le vocabulaire n'est pas trop grand)\n",
        "tokenizer = Tokenizer(oov_token=\"<unk>\") # Ajout d'un token pour les mots inconnus\n",
        "tokenizer.fit_on_texts(text_data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# 2. Déterminer max_sequence_len (peut être calculé sur un échantillon ou l'ensemble des données)\n",
        "# Si le calcul complet de input_sequences fait crasher, vous devrez peut-être estimer ou fixer.\n",
        "# Pour l'exemple, nous allons le faire une fois pour déterminer la longueur maximale.\n",
        "# Si cette partie crashe aussi, vous devrez trouver une façon plus memory-friendly de le faire.\n",
        "sequences_lengths = [len(tokenizer.texts_to_sequences([line])[0]) for line in text_data]\n",
        "max_sequence_len = max(sequences_lengths) if sequences_lengths else 1\n",
        "\n",
        "print(f\"Total words in vocabulary: {total_words}\")\n",
        "print(f\"Max sequence length: {max_sequence_len}\")\n",
        "\n",
        "# --- Stratégie avec un générateur pour l'entraînement ---\n",
        "def data_generator(texts, tokenizer, max_len, total_words, batch_size):\n",
        "    i = 0\n",
        "    while True:\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        if not batch_texts: # Recommence si on a atteint la fin de la liste\n",
        "            i = 0\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "\n",
        "        batch_input_sequences = []\n",
        "        for line in batch_texts:\n",
        "            token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "            for j in range(1, len(token_list)):\n",
        "                n_gram_sequence = token_list[:j+1]\n",
        "                batch_input_sequences.append(n_gram_sequence)\n",
        "\n",
        "        if not batch_input_sequences: # Gérer le cas où le batch est vide\n",
        "            i += batch_size\n",
        "            continue\n",
        "\n",
        "        batch_input_sequences = np.array(pad_sequences(\n",
        "            batch_input_sequences, maxlen=max_len, padding='pre'))\n",
        "\n",
        "        X_batch, y_batch = batch_input_sequences[:, :-1], batch_input_sequences[:, -1]\n",
        "        y_batch = tf.keras.utils.to_categorical(y_batch, num_classes=total_words)\n",
        "\n",
        "        yield X_batch, y_batch\n",
        "        i += batch_size\n",
        "\n",
        "# Définir la taille du batch\n",
        "batch_size = 512 # Commencez petit et augmentez si votre RAM le permet\n",
        "# Divisez vos données en entraînement et validation (bonne pratique)\n",
        "train_data, val_data = train_test_split(text_data, test_size=0.1, random_state=42)\n",
        "\n",
        "# Créer les générateurs\n",
        "train_generator = data_generator(train_data, tokenizer, max_sequence_len, total_words, batch_size)\n",
        "val_generator = data_generator(val_data, tokenizer, max_sequence_len, total_words, batch_size)\n",
        "\n",
        "# Calculer steps_per_epoch et validation_steps\n",
        "# Ceci est une estimation, car chaque phrase génère plusieurs n-grams.\n",
        "# Pour une estimation plus précise, vous devriez précalculer le nombre total de n-grams pour chaque split.\n",
        "# Pour l'instant, une estimation basée sur le nombre de phrases suffit pour commencer.\n",
        "num_train_n_grams_approx = sum(len(tokenizer.texts_to_sequences([line])[0]) - 1 for line in train_data if len(tokenizer.texts_to_sequences([line])[0]) > 1)\n",
        "num_val_n_grams_approx = sum(len(tokenizer.texts_to_sequences([line])[0]) - 1 for line in val_data if len(tokenizer.texts_to_sequences([line])[0]) > 1)\n",
        "\n",
        "steps_per_epoch = int(np.ceil(num_train_n_grams_approx / batch_size))\n",
        "validation_steps = int(np.ceil(num_val_n_grams_approx / batch_size))\n",
        "\n",
        "# Assurez-vous que steps_per_epoch et validation_steps ne sont pas nuls\n",
        "if steps_per_epoch == 0:\n",
        "    steps_per_epoch = 1\n",
        "if validation_steps == 0:\n",
        "    validation_steps = 1\n",
        "\n",
        "print(f\"Estimated training steps per epoch: {steps_per_epoch}\")\n",
        "print(f\"Estimated validation steps: {validation_steps}\")"
      ],
      "metadata": {
        "id": "uAFnxDKg2v_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c16197-b748-4a76-ce18-b570b4499817"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words in vocabulary: 8568\n",
            "Max sequence length: 89\n",
            "Estimated training steps per epoch: 523\n",
            "Estimated validation steps: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Définir le modèle (inchangé, mais notez l'input_length)\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "-2O9gDY227_f",
        "outputId": "ca5bebfc-9bc9-47e7-f373-c079647b6868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraîner le modèle avec le générateur\n",
        "try:\n",
        "    model.fit(train_generator,\n",
        "              steps_per_epoch=steps_per_epoch,\n",
        "              epochs=1,\n",
        "              verbose=1,\n",
        "              validation_data=val_generator,\n",
        "              validation_steps=validation_steps)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during training: {e}\")\n",
        "    print(\"Consider reducing batch_size, sequence_length, or embedding_dim.\")"
      ],
      "metadata": {
        "id": "Bd30WNiZ29V5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "faac59f4-ec85-4f99-ab2f-9428d9d04250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 36/523\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:17\u001b[0m 651ms/step - accuracy: 0.0380 - loss: 8.5706"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1769797561.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Entraîner le modèle avec le générateur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     model.fit(train_generator,\n\u001b[0m\u001b[1;32m      4\u001b[0m               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraîner le modèle avec le générateur\n",
        "try:\n",
        "    model.fit(train_generator,\n",
        "              steps_per_epoch=steps_per_epoch,\n",
        "              epochs=1,\n",
        "              verbose=1,\n",
        "              validation_data=val_generator,\n",
        "              validation_steps=validation_steps)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during training: {e}\")\n",
        "    print(\"Consider reducing batch_size, sequence_length, or embedding_dim.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnxJlHRBFfSX",
        "outputId": "e13bf41c-4008-4b50-b756-26fe3125ffac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 690ms/step - accuracy: 0.0946 - loss: 5.5438 - val_accuracy: 0.1387 - val_loss: 5.2387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraîner le modèle avec le générateur\n",
        "try:\n",
        "    model.fit(train_generator,\n",
        "              steps_per_epoch=steps_per_epoch,\n",
        "              epochs=1,\n",
        "              verbose=1,\n",
        "              validation_data=val_generator,\n",
        "              validation_steps=validation_steps)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during training: {e}\")\n",
        "    print(\"Consider reducing batch_size, sequence_length, or embedding_dim.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7ylTa_bJZH2",
        "outputId": "d5a5efff-8dd7-4dfa-eb0f-f8530d1dbe35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 692ms/step - accuracy: 0.1490 - loss: 5.0252 - val_accuracy: 0.1733 - val_loss: 4.9557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os # Assurez-vous que os est importé si ce n'est pas déjà fait\n",
        "\n",
        "# --- Entraîner le modèle avec le générateur ---\n",
        "try:\n",
        "    print(\"Démarrage de l'entraînement du modèle...\")\n",
        "    model.fit(train_generator,\n",
        "              steps_per_epoch=steps_per_epoch,\n",
        "              epochs=10, # J'ai laissé 10 époques comme dans votre dernier exemple\n",
        "              verbose=1,\n",
        "              validation_data=val_generator,\n",
        "              validation_steps=validation_steps)\n",
        "    print(\"\\nEntraînement terminé avec succès.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nUne erreur s'est produite pendant l'entraînement : {e}\")\n",
        "    print(\"Considérez de réduire davantage batch_size, la taille de l'unité LSTM, ou de plafonner max_sequence_len.\")\n",
        "    # On continue la sauvegarde même en cas d'erreur pour enregistrer l'état partiel du modèle.\n",
        "    # Si le crash est critique (ex: OOM pendant model.fit lui-même), model.save() pourrait échouer aussi.\n",
        "\n",
        "# --- Sauvegarde du modèle après l'entraînement (ou après un crash) ---\n",
        "# Définissez le chemin local où vous voulez sauvegarder le modèle.\n",
        "local_save_dir = './final_model_save/'\n",
        "os.makedirs(local_save_dir, exist_ok=True) # Crée le dossier s'il n'existe pas\n",
        "\n",
        "# Définissez le nom du fichier du modèle.\n",
        "model_filename = 'final_trained_nlp_model.h5'\n",
        "final_model_path = os.path.join(local_save_dir, model_filename)\n",
        "\n",
        "try:\n",
        "    # Sauvegarde du modèle complet (architecture, poids, état de l'optimiseur)\n",
        "    model.save(final_model_path)\n",
        "    print(f\"\\nModèle final sauvegardé avec succès dans : {final_model_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nUne erreur s'est produite lors de la sauvegarde du modèle : {e}\")\n",
        "    print(\"La sauvegarde a échoué. Le modèle pourrait être incomplet ou l'environnement instable.\")\n",
        "\n",
        "# Vous pouvez ajouter le code pour charger et utiliser le modèle ici si vous le souhaitez,\n",
        "# mais il est souvent plus clair de le faire dans une cellule séparée pour la prédiction.\n",
        "\n",
        "# Exemple de code commenté pour charger le modèle :\n",
        "# from tensorflow.keras.models import load_model\n",
        "# try:\n",
        "#     loaded_model = load_model(final_model_path)\n",
        "#     print(f\"Modèle chargé depuis {final_model_path} pour vérification/utilisation.\")\n",
        "#     # Vous pouvez maintenant utiliser 'loaded_model'\n",
        "# except Exception as e:\n",
        "#     print(f\"Impossible de charger le modèle depuis {final_model_path}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PixOXejfIENn",
        "outputId": "abb9db54-8001-47f7-b32b-9715bc0a3a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Démarrage de l'entraînement du modèle...\n",
            "Epoch 1/10\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 690ms/step - accuracy: 0.1853 - loss: 4.7003 - val_accuracy: 0.1970 - val_loss: 4.7932\n",
            "Epoch 2/10\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 732ms/step - accuracy: 0.2079 - loss: 4.4751 - val_accuracy: 0.2126 - val_loss: 4.6876\n",
            "Epoch 3/10\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 690ms/step - accuracy: 0.2260 - loss: 4.3007 - val_accuracy: 0.2248 - val_loss: 4.6104\n",
            "Epoch 4/10\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 690ms/step - accuracy: 0.2405 - loss: 4.1549 - val_accuracy: 0.2347 - val_loss: 4.5560\n",
            "Epoch 5/10\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.2523 - loss: 4.0248"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KtZ_lNpaSL2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate next word predictions\n",
        "seed_text = \"Pizza have different \"\n",
        "next_words = 5\n",
        "\n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences(\n",
        "\t\t[token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted_probs = model.predict(token_list)\n",
        "\tpredicted_word = tokenizer.index_word[np.argmax(predicted_probs)]\n",
        "\tseed_text += \" \" + predicted_word\n",
        "\n",
        "print(\"Next predicted words:\", seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFxXKAKn2-yk",
        "outputId": "c54261aa-65a7-4e46-b282-1ab0e92bd091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Next predicted words: Pizza have different  become a symbol of comfort\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model # <-- Importez load_model\n",
        "\n",
        "# --- 1. Définir le chemin vers votre modèle sauvegardé localement ---\n",
        "# Assurez-vous que ce chemin correspond à l'endroit où vous avez sauvegardé votre modèle.\n",
        "local_save_dir = './final_model_save/'\n",
        "model_filename = 'final_trained_nlp_model.h5'\n",
        "final_model_path = os.path.join(local_save_dir, model_filename)\n",
        "\n",
        "# --- 2. Charger le modèle ---\n",
        "print(f\"Tentative de chargement du modèle depuis : {final_model_path}\")\n",
        "try:\n",
        "    loaded_model = load_model(final_model_path)\n",
        "    print(\"Modèle chargé avec succès pour reprendre l'entraînement !\")\n",
        "    # Affichez un résumé pour vérifier que le modèle est bien chargé\n",
        "    loaded_model.summary()\n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors du chargement du modèle depuis {final_model_path} : {e}\")\n",
        "    print(\"Veuillez vérifier le chemin du fichier et si le fichier .h5 existe.\")\n",
        "    # Sortez ou arrêtez l'exécution si le modèle ne peut pas être chargé\n",
        "    exit()\n",
        "\n",
        "# --- 3. Reprendre l'entraînement ---\n",
        "# Vous avez déjà défini les générateurs (train_generator, val_generator),\n",
        "# les steps_per_epoch, validation_steps, et d'autres paramètres dans les cellules précédentes.\n",
        "# Assurez-vous qu'ils sont toujours disponibles et correctement configurés dans votre environnement.\n",
        "\n",
        "# Vous pouvez également reconfigurer des callbacks si vous le souhaitez pour cette nouvelle phase d'entraînement.\n",
        "# Par exemple, pour continuer à sauvegarder le MEILLEUR modèle sur Drive, ou un nouveau callback de checkpoint local.\n",
        "\n",
        "# Optionnel: Définir un nouveau chemin de sauvegarde pour cette phase d'entraînement,\n",
        "# si vous ne voulez pas écraser l'ancien \"final_trained_nlp_model.h5\" immédiatement.\n",
        "# Ou utilisez un ModelCheckpoint pour sauvegarder à chaque époque comme précédemment.\n",
        "#\n",
        "# Exemple de ModelCheckpoint pour cette nouvelle phase (localement):\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "# continue_save_dir = './continued_training_saves/'\n",
        "# os.makedirs(continue_save_dir, exist_ok=True)\n",
        "# continue_filepath = os.path.join(continue_save_dir, \"continued_model-epoch-{epoch:02d}-val_loss-{val_loss:.4f}.h5\")\n",
        "#\n",
        "# checkpoint_continue = ModelCheckpoint(\n",
        "#     continue_filepath,\n",
        "#     monitor='val_loss',\n",
        "#     verbose=1,\n",
        "#     save_best_only=False, # Sauvegarde chaque époque pour ne rien perdre\n",
        "#     mode='min',\n",
        "#     save_freq='epoch'\n",
        "# )\n",
        "# callbacks_for_continue = [checkpoint_continue]\n",
        "\n",
        "\n",
        "print(\"\\nDémarrage de la reprise de l'entraînement...\")\n",
        "try:\n",
        "    loaded_model.fit(train_generator,\n",
        "                     steps_per_epoch=steps_per_epoch,\n",
        "                     epochs=5, # Entraînez pour quelques époques supplémentaires (ajustez ce nombre)\n",
        "                     verbose=1,\n",
        "                     validation_data=val_generator,\n",
        "                     validation_steps=validation_steps,\n",
        "                     # callbacks=callbacks_for_continue # Activez si vous utilisez le ModelCheckpoint ci-dessus\n",
        "                    )\n",
        "    print(\"\\nReprise de l'entraînement terminée avec succès.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nUne erreur s'est produite pendant la reprise de l'entraînement : {e}\")\n",
        "    print(\"Veuillez vérifier les générateurs de données et les ressources disponibles.\")\n",
        "\n",
        "# --- Optionnel : Sauvegarder le modèle après cette phase d'entraînement continu ---\n",
        "# Si vous n'avez pas utilisé ModelCheckpoint pour cette phase, sauvegardez le modèle final manuellement.\n",
        "new_final_model_path = os.path.join(local_save_dir, 'final_trained_nlp_model_continued.h5')\n",
        "try:\n",
        "    loaded_model.save(new_final_model_path)\n",
        "    print(f\"\\nModèle entraîné en continu sauvegardé dans : {new_final_model_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nErreur lors de la sauvegarde du modèle entraîné en continu : {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "Q7STwYrXVnQt",
        "outputId": "406930d1-9555-4dfa-e5e6-a2859510777b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tentative de chargement du modèle depuis : ./final_model_save/final_trained_nlp_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle chargé avec succès pour reprendre l'entraînement !\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m88\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │        \u001b[38;5;34m85,680\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m71,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8568\u001b[0m)           │     \u001b[38;5;34m1,105,272\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">85,680</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">71,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8568</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,105,272</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,262,122\u001b[0m (4.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,262,122</span> (4.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,262,120\u001b[0m (4.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,262,120</span> (4.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Démarrage de la reprise de l'entraînement...\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Une erreur s'est produite pendant la reprise de l'entraînement : numpy() is only available when eager execution is enabled.\n",
            "Veuillez vérifier les générateurs de données et les ressources disponibles.\n",
            "\n",
            "Modèle entraîné en continu sauvegardé dans : ./final_model_save/final_trained_nlp_model_continued.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model, Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# Importez pad_sequences de keras.utils si celle de preprocessing.sequence pose problème ou n'est pas présente.\n",
        "# Sinon, tf.keras.preprocessing.sequence.pad_sequences est l'approche standard.\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# --- Fonctions et configurations préalables ---\n",
        "\n",
        "def file_to_sentence_list(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    sentences = [sentence.strip() for sentence in re.split(\n",
        "        r'(?<=[.!?])\\s+', text) if sentence.strip()]\n",
        "    return sentences\n",
        "\n",
        "# Charger les données (assurez-vous que 'output.txt' existe)\n",
        "file_path = 'output.txt'\n",
        "text_data = file_to_sentence_list(file_path)\n",
        "\n",
        "# 1. Tokenisation\n",
        "tokenizer = Tokenizer(oov_token=\"<unk>\")\n",
        "tokenizer.fit_on_texts(text_data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# 2. Déterminer max_sequence_len\n",
        "sequences_lengths = [len(tokenizer.texts_to_sequences([line])[0]) for line in text_data]\n",
        "max_sequence_len = max(sequences_lengths) if sequences_lengths else 1\n",
        "\n",
        "print(f\"Total words in vocabulary: {total_words}\")\n",
        "print(f\"Max sequence length: {max_sequence_len}\")\n",
        "\n",
        "# --- Stratégie avec un générateur pour l'entraînement ---\n",
        "def data_generator(texts, tokenizer, max_len, total_words, batch_size):\n",
        "    i = 0\n",
        "    while True:\n",
        "        if i == 0:\n",
        "            np.random.shuffle(texts)\n",
        "\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        if not batch_texts:\n",
        "            i = 0\n",
        "            np.random.shuffle(texts)\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "\n",
        "        batch_input_sequences_temp = []\n",
        "        for line in batch_texts:\n",
        "            token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "            if len(token_list) > 1:\n",
        "                for j in range(1, len(token_list)):\n",
        "                    n_gram_sequence = token_list[:j+1]\n",
        "                    batch_input_sequences_temp.append(n_gram_sequence)\n",
        "\n",
        "        if not batch_input_sequences_temp:\n",
        "            i += batch_size\n",
        "            continue\n",
        "\n",
        "        # Convertir en tableau NumPy D'ABORD, puis effectuer les opérations\n",
        "        padded_sequences_np = np.array(pad_sequences(batch_input_sequences_temp, maxlen=max_len, padding='pre'))\n",
        "\n",
        "        X_batch_np = padded_sequences_np[:, :-1]\n",
        "        y_batch_np = padded_sequences_np[:, -1]\n",
        "\n",
        "        # S'assurer que to_categorical reçoit un tableau NumPy\n",
        "        y_batch_one_hot_np = tf.keras.utils.to_categorical(y_batch_np, num_classes=total_words)\n",
        "\n",
        "        # Enfin, convertir les tableaux NumPy en tenseurs TensorFlow pour la sortie du générateur\n",
        "        X_batch = tf.constant(X_batch_np, dtype=tf.int32)\n",
        "        y_batch = tf.constant(y_batch_one_hot_np, dtype=tf.float32) # Les encodings one-hot sont des floats\n",
        "\n",
        "        yield X_batch, y_batch\n",
        "        i += batch_size\n",
        "\n",
        "# Définir la taille du batch\n",
        "batch_size = 512\n",
        "\n",
        "# Divisez vos données en entraînement et validation\n",
        "train_data, val_data = train_test_split(text_data, test_size=0.1, random_state=42)\n",
        "\n",
        "# Créer les générateurs\n",
        "train_generator = data_generator(train_data, tokenizer, max_sequence_len, total_words, batch_size)\n",
        "val_generator = data_generator(val_data, tokenizer, max_sequence_len, total_words, batch_size)\n",
        "\n",
        "def count_n_grams(texts, tokenizer):\n",
        "    count = 0\n",
        "    for line in texts:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        if len(token_list) > 1:\n",
        "            count += (len(token_list) - 1)\n",
        "    return count\n",
        "\n",
        "num_train_n_grams_approx = count_n_grams(train_data, tokenizer)\n",
        "num_val_n_grams_approx = count_n_grams(val_data, tokenizer)\n",
        "\n",
        "steps_per_epoch = int(np.ceil(num_train_n_grams_approx / batch_size))\n",
        "validation_steps = int(np.ceil(num_val_n_grams_approx / batch_size))\n",
        "\n",
        "if steps_per_epoch == 0:\n",
        "    steps_per_epoch = 1\n",
        "if validation_steps == 0:\n",
        "    validation_steps = 1\n",
        "\n",
        "print(f\"Estimated total n-grams for training: {num_train_n_grams_approx}\")\n",
        "print(f\"Estimated training steps per epoch: {steps_per_epoch}\")\n",
        "print(f\"Estimated total n-grams for validation: {num_val_n_grams_approx}\")\n",
        "print(f\"Estimated validation steps: {validation_steps}\")\n",
        "\n",
        "# --- Section de chargement et entraînement du modèle ---\n",
        "local_save_dir = './final_model_save/'\n",
        "\n",
        "model_filename_keras = 'final_trained_nlp_model.keras'\n",
        "final_model_path_keras = os.path.join(local_save_dir, model_filename_keras)\n",
        "\n",
        "os.makedirs(local_save_dir, exist_ok=True)\n",
        "\n",
        "print(f\"\\nTentative de chargement du modèle depuis : {final_model_path_keras}\")\n",
        "loaded_model = None\n",
        "try:\n",
        "    loaded_model = load_model(final_model_path_keras)\n",
        "    print(\"Modèle chargé avec succès pour reprendre l'entraînement !\")\n",
        "    loaded_model.summary()\n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors du chargement du modèle depuis {final_model_path_keras} : {e}\")\n",
        "    print(\"Veuillez vérifier le chemin du fichier et si le fichier .keras existe.\")\n",
        "\n",
        "    model_filename_h5 = 'final_trained_nlp_model.h5'\n",
        "    final_model_path_h5 = os.path.join(local_save_dir, model_filename_h5)\n",
        "    print(f\"\\nTentative de chargement de l'ancien format HDF5 ({final_model_path_h5})...\")\n",
        "    try:\n",
        "        loaded_model = load_model(final_model_path_h5)\n",
        "        print(\"Modèle HDF5 chargé avec succès. Il sera sauvegardé au nouveau format après l'entraînement.\")\n",
        "        loaded_model.summary()\n",
        "    except Exception as e_h5:\n",
        "        print(f\"Erreur lors du chargement de l'ancien format HDF5 : {e_h5}\")\n",
        "        print(\"\\nRecréation du modèle car le chargement a échoué (ni .keras ni .h5 trouvés ou valides)...\")\n",
        "        embedding_dim = 100\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(total_words, embedding_dim, input_length=max_sequence_len - 1))\n",
        "        model.add(LSTM(150, return_sequences=True))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(LSTM(100))\n",
        "        model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        loaded_model = model\n",
        "        loaded_model.summary()\n",
        "\n",
        "\n",
        "print(\"\\nDémarrage de la reprise de l'entraînement...\")\n",
        "try:\n",
        "    loaded_model.fit(train_generator,\n",
        "                     steps_per_epoch=steps_per_epoch,\n",
        "                     epochs=5,\n",
        "                     verbose=1,\n",
        "                     validation_data=val_generator,\n",
        "                     validation_steps=validation_steps,\n",
        "                    )\n",
        "    print(\"\\nReprise de l'entraînement terminée avec succès.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nUne erreur s'est produite pendant la reprise de l'entraînement : {e}\")\n",
        "    print(\"Veuillez vérifier les générateurs de données et les ressources disponibles.\")\n",
        "\n",
        "try:\n",
        "    if loaded_model:\n",
        "        loaded_model.save(final_model_path_keras)\n",
        "        print(f\"\\nModèle entraîné en continu sauvegardé au format .keras dans : {final_model_path_keras}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nErreur lors de la sauvegarde du modèle entraîné en continu : {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "x3YXkha8W8QG",
        "outputId": "181e2da4-92a9-4d48-e1a3-b5092247807a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total words in vocabulary: 8568\n",
            "Max sequence length: 89\n",
            "Estimated total n-grams for training: 267583\n",
            "Estimated training steps per epoch: 523\n",
            "Estimated total n-grams for validation: 29663\n",
            "Estimated validation steps: 58\n",
            "\n",
            "Tentative de chargement du modèle depuis : ./final_model_save/final_trained_nlp_model.keras\n",
            "Modèle chargé avec succès pour reprendre l'entraînement !\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">85,680</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">71,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8568</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,105,272</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m88\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │        \u001b[38;5;34m85,680\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m71,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8568\u001b[0m)           │     \u001b[38;5;34m1,105,272\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,786,362</span> (14.44 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,786,362\u001b[0m (14.44 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,262,120</span> (4.81 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,262,120\u001b[0m (4.81 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,524,242</span> (9.63 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,524,242\u001b[0m (9.63 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Démarrage de la reprise de l'entraînement...\n",
            "Epoch 1/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 1s/step - accuracy: 0.1859 - loss: 4.6914 - val_accuracy: 0.1974 - val_loss: 4.8164\n",
            "Epoch 2/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 1s/step - accuracy: 0.2087 - loss: 4.4383 - val_accuracy: 0.2142 - val_loss: 4.7287\n",
            "Epoch 3/5\n",
            "\u001b[1m 44/523\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:30\u001b[0m 941ms/step - accuracy: 0.2241 - loss: 4.2870"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3863924757.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nDémarrage de la reprise de l'entraînement...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     loaded_model.fit(train_generator,\n\u001b[0m\u001b[1;32m    157\u001b[0m                      \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_async_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_train_batch_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36m_on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_on_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/callbacks/progbar_logger.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/callbacks/progbar_logger.py\u001b[0m in \u001b[0;36m_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/progbar.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                     avg = backend.convert_to_numpy(\n\u001b[0;32m--> 163\u001b[0;31m                         backend.numpy.mean(\n\u001b[0m\u001b[1;32m    164\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/numpy.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(x, axis, keepdims)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgather_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             )\n\u001b[0;32m--> 677\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m     \u001b[0mori_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0mcompute_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse, ragged)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstandardize_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/tensor_conversion.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m   \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m    162\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/tensor_conversion.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;31m# preferred_dtype = preferred_dtype or dtype_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   return tensor_conversion_registry.convert(\n\u001b[0m\u001b[1;32m    172\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/constant_tensor_conversion.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m   \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    277\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m   const_tensor = ops._create_graph_constant(  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m ) -> ops._EagerTensorBase:\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    loaded_model.save(final_model_path_keras)\n",
        "    print(f\"\\nModèle entraîné en continu sauvegardé au format .keras dans : {final_model_path_keras}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nErreur lors de la sauvegarde du modèle entraîné en continu : {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnipH5BRbjWb",
        "outputId": "3972df03-90a9-425f-83c8-e0e6ec26156d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modèle entraîné en continu sauvegardé au format .keras dans : ./final_model_save/final_trained_nlp_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assurez-vous d'avoir le modèle chargé (loaded_model) et le tokenizer disponibles\n",
        "# Utilisez loaded_model pour la prédiction\n",
        "\n",
        "# Generate next word predictions\n",
        "seed_text = \"hi \" # Texte d'amorçage\n",
        "next_words = 2 # Nombre de mots à prédire\n",
        "\n",
        "# Utilisez le modèle qui a été chargé ou récréé et entraîné\n",
        "model_to_predict = loaded_model\n",
        "\n",
        "print(f\"Seed text: {seed_text}\")\n",
        "print(f\"Predicting {next_words} next words...\")\n",
        "\n",
        "for _ in range(next_words):\n",
        "    # 1. Tokenisation du texte d'amorçage\n",
        "    # Convertit le texte en une séquence d'entiers selon le vocabulaire du tokenizer\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "    # 2. Padding de la séquence\n",
        "    # Le modèle attend une séquence d'une longueur fixe (max_sequence_len-1).\n",
        "    # 'pre' padding ajoute des zéros au début si la séquence est trop courte.\n",
        "    token_list = pad_sequences(\n",
        "        [token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "\n",
        "    # 3. Prédiction du mot suivant\n",
        "    # model.predict() renvoie les probabilités pour chaque mot du vocabulaire.\n",
        "    # On utilise expand_dims si le modèle attend une dimension de batch explicite (par exemple (1, seq_len))\n",
        "    # Cependant, pad_sequences avec [token_list] renvoie déjà (1, seq_len)\n",
        "    predicted_probs = model_to_predict.predict(token_list, verbose=0) # verbose=0 pour ne pas spammer la console\n",
        "\n",
        "    # 4. Obtention du mot le plus probable\n",
        "    # np.argmax() trouve l'indice (ID du mot) de la probabilité la plus élevée.\n",
        "    # tokenizer.index_word convertit cet ID en mot.\n",
        "    predicted_word_index = np.argmax(predicted_probs)\n",
        "    predicted_word = tokenizer.index_word[predicted_word_index]\n",
        "\n",
        "    # 5. Ajout du mot prédit au texte d'amorçage pour la prochaine itération\n",
        "    seed_text += \" \" + predicted_word\n",
        "\n",
        "print(\"Next predicted words:\", seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut57DajBcaoG",
        "outputId": "bd4efa83-e48f-4823-cc40-553cdf9d20af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed text: hi \n",
            "Predicting 2 next words...\n",
            "Next predicted words: hi  is a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model # Nécessaire pour charger\n",
        "\n",
        "# Définissez le chemin où votre modèle est sauvegardé\n",
        "local_save_dir = './final_model_save/'\n",
        "model_filename_keras = 'final_trained_nlp_model.keras' # Assurez-vous d'utiliser le bon format/nom\n",
        "final_model_path_keras = os.path.join(local_save_dir, model_filename_keras)\n",
        "\n",
        "loaded_model = None\n",
        "try:\n",
        "    print(f\"Tentative de chargement du modèle depuis : {final_model_path_keras}\")\n",
        "    loaded_model = load_model(final_model_path_keras)\n",
        "    print(\"Modèle chargé avec succès pour reprendre l'entraînement !\")\n",
        "    loaded_model.summary() # Vérifiez que le modèle est bien chargé et a la bonne structure\n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors du chargement du modèle : {e}\")\n",
        "    print(\"Impossible de charger le modèle. Vérifiez le chemin ou créez un nouveau modèle.\")\n",
        "    # Ici, vous devriez soit sortir (exit()), soit recréer un nouveau modèle\n",
        "    # si vous voulez commencer un entraînement from scratch si aucun modèle n'est trouvé.\n",
        "    # Pour la continuation, il est essentiel qu'un modèle soit chargé.\n",
        "    # (Le code que vous avez déjà inclut la recréation si le chargement échoue)\n",
        "    exit() # Arrête le script si le modèle ne peut pas être chargé"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "J60s2na-cx2c",
        "outputId": "ed69ff1f-0497-45a3-890b-0176da90948a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tentative de chargement du modèle depuis : ./final_model_save/final_trained_nlp_model.keras\n",
            "Modèle chargé avec succès pour reprendre l'entraînement !\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m88\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │        \u001b[38;5;34m85,680\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m71,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8568\u001b[0m)           │     \u001b[38;5;34m1,105,272\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">85,680</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">71,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8568</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,105,272</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,786,362\u001b[0m (14.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,786,362</span> (14.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,262,120\u001b[0m (4.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,262,120</span> (4.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,524,242\u001b[0m (9.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,524,242</span> (9.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDémarrage de la reprise de l'entraînement...\")\n",
        "try:\n",
        "    loaded_model.fit(train_generator,\n",
        "                     steps_per_epoch=steps_per_epoch,\n",
        "                     epochs=5, # C'est le nombre d'époques SUPPLÉMENTAIRES que vous voulez entraîner\n",
        "                               # Si vous avez déjà fait 10 époques et que vous en ajoutez 5 ici,\n",
        "                               # le modèle aura été entraîné pendant 15 époques au total.\n",
        "                     verbose=1,\n",
        "                     validation_data=val_generator,\n",
        "                     validation_steps=validation_steps,\n",
        "                     # callbacks=callbacks_for_continue # Si vous avez des callbacks supplémentaires pour cette phase\n",
        "                    )\n",
        "    print(\"\\nReprise de l'entraînement terminée avec succès.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nUne erreur s'est produite pendant la reprise de l'entraînement : {e}\")\n",
        "    print(\"Veuillez vérifier les générateurs de données et les ressources disponibles.\")\n",
        "\n",
        "# --- Optionnel : Sauvegarder le modèle après cette phase d'entraînement continu ---\n",
        "# Il est toujours bon de sauvegarder le modèle après chaque phase d'entraînement.\n",
        "try:\n",
        "    if loaded_model:\n",
        "        loaded_model.save(final_model_path_keras) # Sauvegarde à nouveau au même emplacement (ou un nouveau)\n",
        "        print(f\"\\nModèle entraîné en continu sauvegardé dans : {final_model_path_keras}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nErreur lors de la sauvegarde du modèle entraîné en continu : {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTTVGmI7c0GP",
        "outputId": "77744e7d-5c3b-482d-858f-0a561cb6c03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Démarrage de la reprise de l'entraînement...\n",
            "Epoch 1/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 1s/step - accuracy: 0.2295 - loss: 4.2322 - val_accuracy: 0.2301 - val_loss: 4.6463\n",
            "Epoch 2/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 1s/step - accuracy: 0.2453 - loss: 4.0673 - val_accuracy: 0.2397 - val_loss: 4.5999\n",
            "Epoch 3/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 1s/step - accuracy: 0.2580 - loss: 3.9320 - val_accuracy: 0.2459 - val_loss: 4.5795\n",
            "Epoch 4/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 1s/step - accuracy: 0.2674 - loss: 3.8271 - val_accuracy: 0.2492 - val_loss: 4.5777\n",
            "Epoch 5/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 1s/step - accuracy: 0.2753 - loss: 3.7410 - val_accuracy: 0.2513 - val_loss: 4.5785\n",
            "\n",
            "Reprise de l'entraînement terminée avec succès.\n",
            "\n",
            "Modèle entraîné en continu sauvegardé dans : ./final_model_save/final_trained_nlp_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDémarrage de la reprise de l'entraînement...\")\n",
        "try:\n",
        "    loaded_model.fit(train_generator,\n",
        "                     steps_per_epoch=steps_per_epoch,\n",
        "                     epochs=5, # C'est le nombre d'époques SUPPLÉMENTAIRES que vous voulez entraîner\n",
        "                               # Si vous avez déjà fait 10 époques et que vous en ajoutez 5 ici,\n",
        "                               # le modèle aura été entraîné pendant 15 époques au total.\n",
        "                     verbose=1,\n",
        "                     validation_data=val_generator,\n",
        "                     validation_steps=validation_steps,\n",
        "                     # callbacks=callbacks_for_continue # Si vous avez des callbacks supplémentaires pour cette phase\n",
        "                    )\n",
        "    print(\"\\nReprise de l'entraînement terminée avec succès.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nUne erreur s'est produite pendant la reprise de l'entraînement : {e}\")\n",
        "    print(\"Veuillez vérifier les générateurs de données et les ressources disponibles.\")\n",
        "\n",
        "# --- Optionnel : Sauvegarder le modèle après cette phase d'entraînement continu ---\n",
        "# Il est toujours bon de sauvegarder le modèle après chaque phase d'entraînement.\n",
        "try:\n",
        "    if loaded_model:\n",
        "        loaded_model.save(final_model_path_keras) # Sauvegarde à nouveau au même emplacement (ou un nouveau)\n",
        "        print(f\"\\nModèle entraîné en continu sauvegardé dans : {final_model_path_keras}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nErreur lors de la sauvegarde du modèle entraîné en continu : {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcaQMQRwoD8W",
        "outputId": "12b0e80c-42aa-405a-f98f-a24a45e4b220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Démarrage de la reprise de l'entraînement...\n",
            "Epoch 1/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 1s/step - accuracy: 0.2829 - loss: 3.6643 - val_accuracy: 0.2552 - val_loss: 4.5868\n",
            "Epoch 2/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 1s/step - accuracy: 0.2902 - loss: 3.5998 - val_accuracy: 0.2574 - val_loss: 4.5991\n",
            "Epoch 3/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 1s/step - accuracy: 0.2960 - loss: 3.5426 - val_accuracy: 0.2586 - val_loss: 4.6192\n",
            "Epoch 4/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 1s/step - accuracy: 0.3014 - loss: 3.4931 - val_accuracy: 0.2586 - val_loss: 4.6347\n",
            "Epoch 5/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 1s/step - accuracy: 0.3063 - loss: 3.4467 - val_accuracy: 0.2589 - val_loss: 4.6547\n",
            "\n",
            "Reprise de l'entraînement terminée avec succès.\n",
            "\n",
            "Modèle entraîné en continu sauvegardé dans : ./final_model_save/final_trained_nlp_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assurez-vous d'avoir le modèle chargé (loaded_model) et le tokenizer disponibles\n",
        "# Utilisez loaded_model pour la prédiction\n",
        "\n",
        "# Generate next word predictions\n",
        "seed_text = \"I love playing with him because he is\" # Texte d'amorçage\n",
        "next_words = 10 # Nombre de mots à prédire\n",
        "\n",
        "# Utilisez le modèle qui a été chargé ou récréé et entraîné\n",
        "model_to_predict = loaded_model\n",
        "\n",
        "print(f\"Seed text: {seed_text}\")\n",
        "print(f\"Predicting {next_words} next words...\")\n",
        "\n",
        "for _ in range(next_words):\n",
        "    # 1. Tokenisation du texte d'amorçage\n",
        "    # Convertit le texte en une séquence d'entiers selon le vocabulaire du tokenizer\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "    # 2. Padding de la séquence\n",
        "    # Le modèle attend une séquence d'une longueur fixe (max_sequence_len-1).\n",
        "    # 'pre' padding ajoute des zéros au début si la séquence est trop courte.\n",
        "    token_list = pad_sequences(\n",
        "        [token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "\n",
        "    # 3. Prédiction du mot suivant\n",
        "    # model.predict() renvoie les probabilités pour chaque mot du vocabulaire.\n",
        "    # On utilise expand_dims si le modèle attend une dimension de batch explicite (par exemple (1, seq_len))\n",
        "    # Cependant, pad_sequences avec [token_list] renvoie déjà (1, seq_len)\n",
        "    predicted_probs = model_to_predict.predict(token_list, verbose=0) # verbose=0 pour ne pas spammer la console\n",
        "\n",
        "    # 4. Obtention du mot le plus probable\n",
        "    # np.argmax() trouve l'indice (ID du mot) de la probabilité la plus élevée.\n",
        "    # tokenizer.index_word convertit cet ID en mot.\n",
        "    predicted_word_index = np.argmax(predicted_probs)\n",
        "    predicted_word = tokenizer.index_word[predicted_word_index]\n",
        "\n",
        "    # 5. Ajout du mot prédit au texte d'amorçage pour la prochaine itération\n",
        "    seed_text += \" \" + predicted_word\n",
        "\n",
        "print(\"Next predicted words:\", seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrfIXQ94zGHG",
        "outputId": "9dc1ae88-e971-4495-dedc-3a291011e2eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed text: I love playing with him because he is\n",
            "Predicting 10 next words...\n",
            "Next predicted words: I love playing with him because he is a very good snowboarder and i have a very disappointing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDémarrage de la reprise de l'entraînement...\")\n",
        "try:\n",
        "    loaded_model.fit(train_generator,\n",
        "                     steps_per_epoch=steps_per_epoch,\n",
        "                     epochs=5, # C'est le nombre d'époques SUPPLÉMENTAIRES que vous voulez entraîner\n",
        "                               # Si vous avez déjà fait 10 époques et que vous en ajoutez 5 ici,\n",
        "                               # le modèle aura été entraîné pendant 15 époques au total.\n",
        "                     verbose=1,\n",
        "                     validation_data=val_generator,\n",
        "                     validation_steps=validation_steps,\n",
        "                     # callbacks=callbacks_for_continue # Si vous avez des callbacks supplémentaires pour cette phase\n",
        "                    )\n",
        "    print(\"\\nReprise de l'entraînement terminée avec succès.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nUne erreur s'est produite pendant la reprise de l'entraînement : {e}\")\n",
        "    print(\"Veuillez vérifier les générateurs de données et les ressources disponibles.\")\n",
        "\n",
        "# --- Optionnel : Sauvegarder le modèle après cette phase d'entraînement continu ---\n",
        "# Il est toujours bon de sauvegarder le modèle après chaque phase d'entraînement.\n",
        "try:\n",
        "    if loaded_model:\n",
        "        loaded_model.save(final_model_path_keras) # Sauvegarde à nouveau au même emplacement (ou un nouveau)\n",
        "        print(f\"\\nModèle entraîné en continu sauvegardé dans : {final_model_path_keras}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nErreur lors de la sauvegarde du modèle entraîné en continu : {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL7jJ3Vl2vwF",
        "outputId": "67b90e1d-9932-4e5d-d04d-9b1938020d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Démarrage de la reprise de l'entraînement...\n",
            "Epoch 1/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m554s\u001b[0m 1s/step - accuracy: 0.3110 - loss: 3.4051 - val_accuracy: 0.2597 - val_loss: 4.6792\n",
            "Epoch 2/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDémarrage de la reprise de l'entraînement...\")\n",
        "try:\n",
        "    loaded_model.fit(train_generator,\n",
        "                     steps_per_epoch=steps_per_epoch,\n",
        "                     epochs=5, # C'est le nombre d'époques SUPPLÉMENTAIRES que vous voulez entraîner\n",
        "                               # Si vous avez déjà fait 10 époques et que vous en ajoutez 5 ici,\n",
        "                               # le modèle aura été entraîné pendant 15 époques au total.\n",
        "                     verbose=1,\n",
        "                     validation_data=val_generator,\n",
        "                     validation_steps=validation_steps,\n",
        "                     # callbacks=callbacks_for_continue # Si vous avez des callbacks supplémentaires pour cette phase\n",
        "                    )\n",
        "    print(\"\\nReprise de l'entraînement terminée avec succès.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nUne erreur s'est produite pendant la reprise de l'entraînement : {e}\")\n",
        "    print(\"Veuillez vérifier les générateurs de données et les ressources disponibles.\")\n",
        "\n",
        "# --- Optionnel : Sauvegarder le modèle après cette phase d'entraînement continu ---\n",
        "# Il est toujours bon de sauvegarder le modèle après chaque phase d'entraînement.\n",
        "try:\n",
        "    if loaded_model:\n",
        "        loaded_model.save(final_model_path_keras) # Sauvegarde à nouveau au même emplacement (ou un nouveau)\n",
        "        print(f\"\\nModèle entraîné en continu sauvegardé dans : {final_model_path_keras}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nErreur lors de la sauvegarde du modèle entraîné en continu : {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXabF_3L7ZhW",
        "outputId": "dc2cea26-37a7-4bfa-b14c-8d58f2028cce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Démarrage de la reprise de l'entraînement...\n",
            "Epoch 1/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 691ms/step - accuracy: 0.3108 - loss: 3.4060 - val_accuracy: 0.2588 - val_loss: 4.6781\n",
            "Epoch 2/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 686ms/step - accuracy: 0.3144 - loss: 3.3718 - val_accuracy: 0.2600 - val_loss: 4.7025\n",
            "Epoch 3/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 691ms/step - accuracy: 0.3186 - loss: 3.3369 - val_accuracy: 0.2603 - val_loss: 4.7313\n",
            "Epoch 4/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 687ms/step - accuracy: 0.3221 - loss: 3.3091 - val_accuracy: 0.2605 - val_loss: 4.7496\n",
            "Epoch 5/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 732ms/step - accuracy: 0.3260 - loss: 3.2764 - val_accuracy: 0.2608 - val_loss: 4.7729\n",
            "\n",
            "Reprise de l'entraînement terminée avec succès.\n",
            "\n",
            "Modèle entraîné en continu sauvegardé dans : ./final_model_save/final_trained_nlp_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assurez-vous d'avoir le modèle chargé (loaded_model) et le tokenizer disponibles\n",
        "# Utilisez loaded_model pour la prédiction\n",
        "\n",
        "# Generate next word predictions\n",
        "seed_text = \"I was sad last day in the festival i felt\" # Texte d'amorçage\n",
        "next_words = 6 # Nombre de mots à prédire\n",
        "\n",
        "# Utilisez le modèle qui a été chargé ou récréé et entraîné\n",
        "model_to_predict = loaded_model\n",
        "\n",
        "print(f\"Seed text: {seed_text}\")\n",
        "print(f\"Predicting {next_words} next words...\")\n",
        "\n",
        "for _ in range(next_words):\n",
        "    # 1. Tokenisation du texte d'amorçage\n",
        "    # Convertit le texte en une séquence d'entiers selon le vocabulaire du tokenizer\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "    # 2. Padding de la séquence\n",
        "    # Le modèle attend une séquence d'une longueur fixe (max_sequence_len-1).\n",
        "    # 'pre' padding ajoute des zéros au début si la séquence est trop courte.\n",
        "    token_list = pad_sequences(\n",
        "        [token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "\n",
        "    # 3. Prédiction du mot suivant\n",
        "    # model.predict() renvoie les probabilités pour chaque mot du vocabulaire.\n",
        "    # On utilise expand_dims si le modèle attend une dimension de batch explicite (par exemple (1, seq_len))\n",
        "    # Cependant, pad_sequences avec [token_list] renvoie déjà (1, seq_len)\n",
        "    predicted_probs = model_to_predict.predict(token_list, verbose=0) # verbose=0 pour ne pas spammer la console\n",
        "\n",
        "    # 4. Obtention du mot le plus probable\n",
        "    # np.argmax() trouve l'indice (ID du mot) de la probabilité la plus élevée.\n",
        "    # tokenizer.index_word convertit cet ID en mot.\n",
        "    predicted_word_index = np.argmax(predicted_probs)\n",
        "    predicted_word = tokenizer.index_word[predicted_word_index]\n",
        "\n",
        "    # 5. Ajout du mot prédit au texte d'amorçage pour la prochaine itération\n",
        "    seed_text += \" \" + predicted_word\n",
        "\n",
        "print(\"Next predicted words:\", seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qfTdODjDt1f",
        "outputId": "e4327dd8-1e8f-41f5-9efb-f8034a2e748f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed text: I was sad last day in the festival i felt\n",
            "Predicting 6 next words...\n",
            "Next predicted words: I was sad last day in the festival i felt very disappointed with the musical show\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDémarrage de la reprise de l'entraînement...\")\n",
        "try:\n",
        "    loaded_model.fit(train_generator,\n",
        "                     steps_per_epoch=steps_per_epoch,\n",
        "                     epochs=5, # C'est le nombre d'époques SUPPLÉMENTAIRES que vous voulez entraîner\n",
        "                               # Si vous avez déjà fait 10 époques et que vous en ajoutez 5 ici,\n",
        "                               # le modèle aura été entraîné pendant 15 époques au total.\n",
        "                     verbose=1,\n",
        "                     validation_data=val_generator,\n",
        "                     validation_steps=validation_steps,\n",
        "                     # callbacks=callbacks_for_continue # Si vous avez des callbacks supplémentaires pour cette phase\n",
        "                    )\n",
        "    print(\"\\nReprise de l'entraînement terminée avec succès.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nUne erreur s'est produite pendant la reprise de l'entraînement : {e}\")\n",
        "    print(\"Veuillez vérifier les générateurs de données et les ressources disponibles.\")\n",
        "\n",
        "# --- Optionnel : Sauvegarder le modèle après cette phase d'entraînement continu ---\n",
        "# Il est toujours bon de sauvegarder le modèle après chaque phase d'entraînement.\n",
        "try:\n",
        "    if loaded_model:\n",
        "        loaded_model.save(final_model_path_keras) # Sauvegarde à nouveau au même emplacement (ou un nouveau)\n",
        "        print(f\"\\nModèle entraîné en continu sauvegardé dans : {final_model_path_keras}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nErreur lors de la sauvegarde du modèle entraîné en continu : {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44L1lp5fDpjA",
        "outputId": "63a0b9c2-7eea-4e6a-94a0-d456e46d3eea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Démarrage de la reprise de l'entraînement...\n",
            "Epoch 1/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 693ms/step - accuracy: 0.3293 - loss: 3.2506 - val_accuracy: 0.2612 - val_loss: 4.8004\n",
            "Epoch 2/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 687ms/step - accuracy: 0.3327 - loss: 3.2247 - val_accuracy: 0.2606 - val_loss: 4.8223\n",
            "Epoch 3/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 684ms/step - accuracy: 0.3354 - loss: 3.2034 - val_accuracy: 0.2612 - val_loss: 4.8479\n",
            "Epoch 4/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 732ms/step - accuracy: 0.3370 - loss: 3.1880 - val_accuracy: 0.2609 - val_loss: 4.8722\n",
            "Epoch 5/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 730ms/step - accuracy: 0.3409 - loss: 3.1599 - val_accuracy: 0.2600 - val_loss: 4.9035\n",
            "\n",
            "Reprise de l'entraînement terminée avec succès.\n",
            "\n",
            "Modèle entraîné en continu sauvegardé dans : ./final_model_save/final_trained_nlp_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDémarrage de la reprise de l'entraînement...\")\n",
        "try:\n",
        "    loaded_model.fit(train_generator,\n",
        "                     steps_per_epoch=steps_per_epoch,\n",
        "                     epochs=5, # C'est le nombre d'époques SUPPLÉMENTAIRES que vous voulez entraîner\n",
        "                               # Si vous avez déjà fait 10 époques et que vous en ajoutez 5 ici,\n",
        "                               # le modèle aura été entraîné pendant 15 époques au total.\n",
        "                     verbose=1,\n",
        "                     validation_data=val_generator,\n",
        "                     validation_steps=validation_steps,\n",
        "                     # callbacks=callbacks_for_continue # Si vous avez des callbacks supplémentaires pour cette phase\n",
        "                    )\n",
        "    print(\"\\nReprise de l'entraînement terminée avec succès.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nUne erreur s'est produite pendant la reprise de l'entraînement : {e}\")\n",
        "    print(\"Veuillez vérifier les générateurs de données et les ressources disponibles.\")\n",
        "\n",
        "# --- Optionnel : Sauvegarder le modèle après cette phase d'entraînement continu ---\n",
        "# Il est toujours bon de sauvegarder le modèle après chaque phase d'entraînement.\n",
        "try:\n",
        "    if loaded_model:\n",
        "        loaded_model.save(final_model_path_keras) # Sauvegarde à nouveau au même emplacement (ou un nouveau)\n",
        "        print(f\"\\nModèle entraîné en continu sauvegardé dans : {final_model_path_keras}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nErreur lors de la sauvegarde du modèle entraîné en continu : {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4euehxvMKnn",
        "outputId": "f9e2c49e-1eaa-4b64-9286-50b02706d10a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Démarrage de la reprise de l'entraînement...\n",
            "Epoch 1/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 694ms/step - accuracy: 0.3428 - loss: 3.1426 - val_accuracy: 0.2605 - val_loss: 4.9204\n",
            "Epoch 2/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 694ms/step - accuracy: 0.3456 - loss: 3.1219 - val_accuracy: 0.2597 - val_loss: 4.9451\n",
            "Epoch 3/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 732ms/step - accuracy: 0.3477 - loss: 3.1053 - val_accuracy: 0.2614 - val_loss: 4.9639\n",
            "Epoch 4/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 731ms/step - accuracy: 0.3504 - loss: 3.0866 - val_accuracy: 0.2578 - val_loss: 4.9911\n",
            "Epoch 5/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 731ms/step - accuracy: 0.3515 - loss: 3.0772 - val_accuracy: 0.2585 - val_loss: 5.0108\n",
            "\n",
            "Reprise de l'entraînement terminée avec succès.\n",
            "\n",
            "Modèle entraîné en continu sauvegardé dans : ./final_model_save/final_trained_nlp_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDémarrage de la reprise de l'entraînement...\")\n",
        "try:\n",
        "    loaded_model.fit(train_generator,\n",
        "                     steps_per_epoch=steps_per_epoch,\n",
        "                     epochs=5, # C'est le nombre d'époques SUPPLÉMENTAIRES que vous voulez entraîner\n",
        "                               # Si vous avez déjà fait 10 époques et que vous en ajoutez 5 ici,\n",
        "                               # le modèle aura été entraîné pendant 15 époques au total.\n",
        "                     verbose=1,\n",
        "                     validation_data=val_generator,\n",
        "                     validation_steps=validation_steps,\n",
        "                     # callbacks=callbacks_for_continue # Si vous avez des callbacks supplémentaires pour cette phase\n",
        "                    )\n",
        "    print(\"\\nReprise de l'entraînement terminée avec succès.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nUne erreur s'est produite pendant la reprise de l'entraînement : {e}\")\n",
        "    print(\"Veuillez vérifier les générateurs de données et les ressources disponibles.\")\n",
        "\n",
        "# --- Optionnel : Sauvegarder le modèle après cette phase d'entraînement continu ---\n",
        "# Il est toujours bon de sauvegarder le modèle après chaque phase d'entraînement.\n",
        "try:\n",
        "    if loaded_model:\n",
        "        loaded_model.save(final_model_path_keras) # Sauvegarde à nouveau au même emplacement (ou un nouveau)\n",
        "        print(f\"\\nModèle entraîné en continu sauvegardé dans : {final_model_path_keras}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nErreur lors de la sauvegarde du modèle entraîné en continu : {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33nwjLWaTarc",
        "outputId": "95870861-0fc0-49d5-b789-35053d7239d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Démarrage de la reprise de l'entraînement...\n",
            "Epoch 1/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 694ms/step - accuracy: 0.3547 - loss: 3.0548 - val_accuracy: 0.2577 - val_loss: 5.0316\n",
            "Epoch 2/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 732ms/step - accuracy: 0.3565 - loss: 3.0433 - val_accuracy: 0.2567 - val_loss: 5.0573\n",
            "Epoch 3/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 731ms/step - accuracy: 0.3571 - loss: 3.0345 - val_accuracy: 0.2586 - val_loss: 5.0783\n",
            "Epoch 4/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 730ms/step - accuracy: 0.3599 - loss: 3.0153 - val_accuracy: 0.2582 - val_loss: 5.1061\n",
            "Epoch 5/5\n",
            "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 731ms/step - accuracy: 0.3609 - loss: 3.0070 - val_accuracy: 0.2583 - val_loss: 5.1167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_save_dir = './final_model_save/'\n",
        "model_filename_keras = 'final_trained_nlp_model.keras' # Assurez-vous d'utiliser le bon format/nom\n",
        "final_model_path_keras = os.path.join(local_save_dir, model_filename_keras)\n",
        "loaded_model.save(final_model_path_keras) # Sauvegarde à nouveau au même emplacement (ou un nouveau)\n",
        "print(f\"\\nModèle entraîné en continu sauvegardé dans : {final_model_path_keras}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Kp8YhC_ObCRL",
        "outputId": "32d2e71e-62fd-4152-d08e-42535c827339"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-3992040528.py, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3992040528.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    loaded_model.save(final_model_path_keras) # Sauvegarde à nouveau au même emplacement (ou un nouveau)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    }
  ]
}